{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#预测单张图片\n",
    "#-------------------------------------#\n",
    "#       创建YOLO类\n",
    "#-------------------------------------#\n",
    "import cv2\n",
    "import numpy as np\n",
    "import colorsys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from PIL import Image,ImageFont, ImageDraw\n",
    "from torch.autograd import Variable\n",
    "from nets.yolo4 import YoloBody\n",
    "from utils.utils import non_max_suppression, bbox_iou, DecodeBox,letterbox_image,yolo_correct_boxes\n",
    "#--------------------------------------------#\n",
    "#   使用自己训练好的模型预测需要修改2个参数\n",
    "#   model_path和classes_path都需要修改！\n",
    "#--------------------------------------------#\n",
    "class YOLO(object):\n",
    "    _defaults = {\n",
    "        \"model_path\": 'logs/yolo4_DDE_weights_subgraph.pth',\n",
    "        \"anchors_path\": 'model_data/yolo_anchors.txt',\n",
    "        \"classes_path\": 'model_data/new_classes.txt',\n",
    "        \"model_image_size\" : (608, 608, 3),\n",
    "        \"confidence\": 0.5,\n",
    "        \"cuda\": True\n",
    "    }\n",
    "\n",
    "    @classmethod\n",
    "    def get_defaults(cls, n):\n",
    "        if n in cls._defaults:\n",
    "            return cls._defaults[n]\n",
    "        else:\n",
    "            return \"Unrecognized attribute name '\" + n + \"'\"\n",
    "\n",
    "    #---------------------------------------------------#\n",
    "    #   初始化YOLO\n",
    "    #---------------------------------------------------#\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(self._defaults)\n",
    "        self.class_names = self._get_class()\n",
    "        self.anchors = self._get_anchors()\n",
    "        self.generate()\n",
    "    #---------------------------------------------------#\n",
    "    #   获得所有的分类\n",
    "    #---------------------------------------------------#\n",
    "    def _get_class(self):\n",
    "        classes_path = os.path.expanduser(self.classes_path)\n",
    "        with open(classes_path) as f:\n",
    "            class_names = f.readlines()\n",
    "        class_names = [c.strip() for c in class_names]\n",
    "        return class_names\n",
    "    \n",
    "    #---------------------------------------------------#\n",
    "    #   获得所有的先验框\n",
    "    #---------------------------------------------------#\n",
    "    def _get_anchors(self):\n",
    "        anchors_path = os.path.expanduser(self.anchors_path)\n",
    "        with open(anchors_path) as f:\n",
    "            anchors = f.readline()\n",
    "        anchors = [float(x) for x in anchors.split(',')]\n",
    "        return np.array(anchors).reshape([-1, 3, 2])[::-1,:,:]\n",
    "\n",
    "    #---------------------------------------------------#\n",
    "    #   获得所有的分类\n",
    "    #---------------------------------------------------#\n",
    "    def generate(self):\n",
    "        \n",
    "        self.net = YoloBody(len(self.anchors[0]),len(self.class_names)).eval()\n",
    "\n",
    "        # 加快模型训练的效率\n",
    "        print('Loading weights into state dict...')\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        state_dict = torch.load(self.model_path, map_location=device)\n",
    "        self.net.load_state_dict(state_dict)\n",
    "        #checkpoint = torch.load(self.model_path, map_location=device)\n",
    "        #self.net.load_state_dict(checkpoint['model'])\n",
    "        \n",
    "        if self.cuda:\n",
    "            os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "            self.net = nn.DataParallel(self.net)\n",
    "            self.net = self.net.cuda()\n",
    "    \n",
    "        print('Finished!')\n",
    "\n",
    "        self.yolo_decodes = []\n",
    "        for i in range(3):\n",
    "            self.yolo_decodes.append(DecodeBox(self.anchors[i], len(self.class_names),  (self.model_image_size[1], self.model_image_size[0])))\n",
    "\n",
    "\n",
    "        print('{} model, anchors, and classes loaded.'.format(self.model_path))\n",
    "        # 画框设置不同的颜色\n",
    "        hsv_tuples = [(x / len(self.class_names), 1., 1.)\n",
    "                      for x in range(len(self.class_names))]\n",
    "        self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "        self.colors = list(\n",
    "            map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n",
    "                self.colors))\n",
    "\n",
    "    #---------------------------------------------------#\n",
    "    #   检测图片\n",
    "    #---------------------------------------------------#\n",
    "    def detect_image(self, image):\n",
    "        image_shape = np.array(np.shape(image)[0:2])\n",
    "\n",
    "        crop_img = np.array(letterbox_image(image, (self.model_image_size[0],self.model_image_size[1])))\n",
    "        photo = np.array(crop_img,dtype = np.float32)\n",
    "        photo /= 255.0\n",
    "        photo = np.transpose(photo, (2, 0, 1))\n",
    "        photo = photo.astype(np.float32)\n",
    "        images = []\n",
    "        images.append(photo)\n",
    "        images = np.asarray(images)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            images = torch.from_numpy(images)\n",
    "            if self.cuda:\n",
    "                images = images.cuda()\n",
    "            outputs = self.net(images)\n",
    "            \n",
    "        output_list = []\n",
    "        for i in range(3):\n",
    "            output_list.append(self.yolo_decodes[i](outputs[i]))\n",
    "        output = torch.cat(output_list, 1)\n",
    "        batch_detections = non_max_suppression(output, len(self.class_names),\n",
    "                                                conf_thres=self.confidence,\n",
    "                                                nms_thres=0.3)\n",
    "        try:\n",
    "            batch_detections = batch_detections[0].cpu().numpy()\n",
    "        except:\n",
    "            return image\n",
    "            \n",
    "        top_index = batch_detections[:,4]*batch_detections[:,5] > self.confidence\n",
    "        top_conf = batch_detections[top_index,4]*batch_detections[top_index,5]\n",
    "        top_label = np.array(batch_detections[top_index,-1],np.int32)\n",
    "        top_bboxes = np.array(batch_detections[top_index,:4])\n",
    "        top_xmin, top_ymin, top_xmax, top_ymax = np.expand_dims(top_bboxes[:,0],-1),np.expand_dims(top_bboxes[:,1],-1),np.expand_dims(top_bboxes[:,2],-1),np.expand_dims(top_bboxes[:,3],-1)\n",
    "\n",
    "        # 去掉灰条\n",
    "        boxes = yolo_correct_boxes(top_ymin,top_xmin,top_ymax,top_xmax,np.array([self.model_image_size[0],self.model_image_size[1]]),image_shape)\n",
    "\n",
    "        font = ImageFont.truetype(font='model_data/simhei.ttf',size=np.floor(3e-2 * np.shape(image)[1] + 0.5).astype('int32'))\n",
    "\n",
    "        thickness = (np.shape(image)[0] + np.shape(image)[1]) // self.model_image_size[0]\n",
    "\n",
    "        for i, c in enumerate(top_label):\n",
    "            predicted_class = self.class_names[c]\n",
    "            score = top_conf[i]\n",
    "\n",
    "            top, left, bottom, right = boxes[i]\n",
    "            top = top - 5\n",
    "            left = left - 5\n",
    "            bottom = bottom + 5\n",
    "            right = right + 5\n",
    "\n",
    "            top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "            left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "            bottom = min(np.shape(image)[0], np.floor(bottom + 0.5).astype('int32'))\n",
    "            right = min(np.shape(image)[1], np.floor(right + 0.5).astype('int32'))\n",
    "\n",
    "            # 画框框\n",
    "            label = '{} {:.2f}'.format(predicted_class, score)\n",
    "            draw = ImageDraw.Draw(image)\n",
    "            label_size = draw.textsize(label, font)\n",
    "            label = label.encode('utf-8')\n",
    "            print(label)\n",
    "            \n",
    "            if top - label_size[1] >= 0:\n",
    "                text_origin = np.array([left, top - label_size[1]])\n",
    "            else:\n",
    "                text_origin = np.array([left, top + 1])\n",
    "\n",
    "            for i in range(thickness):\n",
    "                draw.rectangle(\n",
    "                    [left + i, top + i, right - i, bottom - i],\n",
    "                    outline=self.colors[self.class_names.index(predicted_class)])\n",
    "            draw.rectangle(\n",
    "                [tuple(text_origin), tuple(text_origin + label_size)],\n",
    "                fill=self.colors[self.class_names.index(predicted_class)])\n",
    "            draw.text(text_origin, str(label,'UTF-8'), fill=(0, 0, 0), font=font)\n",
    "            del draw\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading weights into state dict...\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "logs/yolo4_DDE_weights_subgraph.pth is a zip archive (did you mean to use torch.jit.load()?)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mD:\\ProgrammingEnvironment\\Anaconda3\\lib\\tarfile.py\u001b[0m in \u001b[0;36mnti\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ascii\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"0\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 8: 'build_te'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidHeaderError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mD:\\ProgrammingEnvironment\\Anaconda3\\lib\\tarfile.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2288\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2289\u001b[1;33m                 \u001b[0mtarinfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromtarfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2290\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mEOFHeaderError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgrammingEnvironment\\Anaconda3\\lib\\tarfile.py\u001b[0m in \u001b[0;36mfromtarfile\u001b[1;34m(cls, tarfile)\u001b[0m\n\u001b[0;32m   1094\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBLOCKSIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1095\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrombuf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1096\u001b[0m         \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mBLOCKSIZE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgrammingEnvironment\\Anaconda3\\lib\\tarfile.py\u001b[0m in \u001b[0;36mfrombuf\u001b[1;34m(cls, buf, encoding, errors)\u001b[0m\n\u001b[0;32m   1036\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m         \u001b[0mchksum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnti\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m148\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m156\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mchksum\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcalc_chksums\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgrammingEnvironment\\Anaconda3\\lib\\tarfile.py\u001b[0m in \u001b[0;36mnti\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mInvalidHeaderError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"invalid header\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidHeaderError\u001b[0m: invalid header",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mReadError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mD:\\ProgrammingEnvironment\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mlegacy_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTarError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgrammingEnvironment\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mlegacy_load\u001b[1;34m(f)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 467\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mclosing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPAX_FORMAT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    468\u001b[0m                 \u001b[0mmkdtemp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtmpdir\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgrammingEnvironment\\Anaconda3\\lib\\tarfile.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[0;32m   1590\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCompressionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"unknown compression type %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mcomptype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1591\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgrammingEnvironment\\Anaconda3\\lib\\tarfile.py\u001b[0m in \u001b[0;36mtaropen\u001b[1;34m(cls, name, mode, fileobj, **kwargs)\u001b[0m\n\u001b[0;32m   1620\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mode must be 'r', 'a', 'w' or 'x'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1621\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgrammingEnvironment\\Anaconda3\\lib\\tarfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, fileobj, format, tarinfo, dereference, ignore_zeros, encoding, errors, pax_headers, debug, errorlevel, copybufsize)\u001b[0m\n\u001b[0;32m   1483\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfirstmember\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1484\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfirstmember\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgrammingEnvironment\\Anaconda3\\lib\\tarfile.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2300\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffset\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2301\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mReadError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2302\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mEmptyHeaderError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mReadError\u001b[0m: invalid header",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e282e3a901c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0myolo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'img/test1.png'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-4750d6dc0b50>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manchors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_anchors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[1;31m#---------------------------------------------------#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;31m#   获得所有的分类\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-4750d6dc0b50>\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loading weights into state dict...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[0mstate_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;31m#checkpoint = torch.load(self.model_path, map_location=device)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgrammingEnvironment\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgrammingEnvironment\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    558\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m                 \u001b[1;31m# .zip is used for torch.jit.save and will throw an un-pickling error here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} is a zip archive (did you mean to use torch.jit.load()?)\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m             \u001b[1;31m# if not a tarfile, reset file offset and proceed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: logs/yolo4_DDE_weights_subgraph.pth is a zip archive (did you mean to use torch.jit.load()?)"
     ]
    }
   ],
   "source": [
    "#-------------------------------------#\n",
    "#       对单张图片进行预测\n",
    "#-------------------------------------#\n",
    "from PIL import Image\n",
    "\n",
    "yolo = YOLO()\n",
    "\n",
    "img = 'img/test1.png'\n",
    "try:\n",
    "    image = Image.open(img)\n",
    "except:\n",
    "    print('Open Error! Try again!')\n",
    "else:\n",
    "    r_image = yolo.detect_image(image)\n",
    "    r_image.show()\n",
    "    r_image.save('img/dr_test1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed!\n"
     ]
    }
   ],
   "source": [
    "#生成input下的ground-truth文件\n",
    "#-------------------------------------#\n",
    "#       mAP所需文件计算代码\n",
    "#       具体教程请查看Bilibili\n",
    "#       Bubbliiiing\n",
    "#-------------------------------------#\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "image_ids = open('VOCdevkit/VOC2007/ImageSets/Main/test_465_1.txt').read().strip().split()\n",
    "\n",
    "if not os.path.exists(\"./input\"):\n",
    "    os.makedirs(\"./input\")\n",
    "if not os.path.exists(\"./input/ground-truth\"):\n",
    "    os.makedirs(\"./input/ground-truth\")\n",
    "\n",
    "for image_id in image_ids:\n",
    "    with open(\"./input/ground-truth/\"+image_id+\".txt\", \"w\") as new_f:\n",
    "        root = ET.parse(\"VOCdevkit/VOC2007/Annotations_465/\"+image_id+\".xml\").getroot()\n",
    "        for obj in root.findall('object'):\n",
    "            if obj.find('difficult')!=None:\n",
    "                difficult = obj.find('difficult').text\n",
    "                if int(difficult)==1:\n",
    "                    continue\n",
    "            obj_name = obj.find('name').text\n",
    "            bndbox = obj.find('bndbox')\n",
    "            left = bndbox.find('xmin').text\n",
    "            top = bndbox.find('ymin').text\n",
    "            right = bndbox.find('xmax').text\n",
    "            bottom = bndbox.find('ymax').text\n",
    "            new_f.write(\"%s %s %s %s %s\\n\" % (obj_name, left, top, right, bottom))\n",
    "print(\"Conversion completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights into state dict...\n",
      "Finished!\n",
      "logs/yolo4_DDE_weights_352_5000.pth model, anchors, and classes loaded.\n",
      "(2, 4)\n",
      "c1  done!\n",
      "(1, 4)\n",
      "c2  done!\n",
      "(9, 4)\n",
      "g5  done!\n",
      "(14, 4)\n",
      "g55  done!\n",
      "(18, 4)\n",
      "g56  done!\n",
      "(7, 4)\n",
      "g57  done!\n",
      "(13, 4)\n",
      "g80  done!\n",
      "(6, 4)\n",
      "gg1  done!\n",
      "(26, 4)\n",
      "gg2  done!\n",
      "(3, 4)\n",
      "gg34  done!\n",
      "(2, 4)\n",
      "gg35  done!\n",
      "(2, 4)\n",
      "gg36  done!\n",
      "(5, 4)\n",
      "gg63  done!\n",
      "(6, 4)\n",
      "gg65  done!\n",
      "(5, 4)\n",
      "gg90  done!\n",
      "(3, 4)\n",
      "gg91  done!\n",
      "(5, 4)\n",
      "gg92  done!\n",
      "(10, 4)\n",
      "gg122  done!\n",
      "(14, 4)\n",
      "gg123  done!\n",
      "(6, 4)\n",
      "gg124  done!\n",
      "(12, 4)\n",
      "z14  done!\n",
      "(8, 4)\n",
      "g61  done!\n",
      "(14, 4)\n",
      "z95  done!\n",
      "(2, 4)\n",
      "gg28  done!\n",
      "(5, 4)\n",
      "gg15  done!\n",
      "(14, 4)\n",
      "z73  done!\n",
      "(3, 4)\n",
      "gg17  done!\n",
      "(7, 4)\n",
      "z186  done!\n",
      "(14, 4)\n",
      "z203  done!\n",
      "(13, 4)\n",
      "g78  done!\n",
      "(10, 4)\n",
      "z184  done!\n",
      "(12, 4)\n",
      "z94  done!\n",
      "(7, 4)\n",
      "z29  done!\n",
      "(5, 4)\n",
      "z47  done!\n",
      "(10, 4)\n",
      "z40  done!\n",
      "Conversion completed!\n"
     ]
    }
   ],
   "source": [
    "#生成input下的detection-results文件和images-optional文件\n",
    "#-------------------------------------#\n",
    "#       mAP所需文件计算代码\n",
    "#       具体教程请查看Bilibili\n",
    "#       Bubbliiiing\n",
    "#-------------------------------------#\n",
    "import cv2\n",
    "import numpy as np\n",
    "import colorsys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "from nets.yolo4 import YoloBody\n",
    "from PIL import Image,ImageFont, ImageDraw\n",
    "from utils.utils import non_max_suppression, bbox_iou, DecodeBox,letterbox_image,yolo_correct_boxes\n",
    "\n",
    "class mAP_Yolo(YOLO):\n",
    "    #---------------------------------------------------#\n",
    "    #   检测图片\n",
    "    #---------------------------------------------------#\n",
    "    def detect_image(self,image_id,image):\n",
    "        self.confidence = 0.05\n",
    "        f = open(\"./input/detection-results/\"+image_id+\".txt\",\"w\") \n",
    "        image_shape = np.array(np.shape(image)[0:2])\n",
    "\n",
    "        crop_img = np.array(letterbox_image(image, (self.model_image_size[0],self.model_image_size[1])))\n",
    "        photo = np.array(crop_img,dtype = np.float32)\n",
    "        photo /= 255.0\n",
    "        photo = np.transpose(photo, (2, 0, 1))\n",
    "        photo = photo.astype(np.float32)\n",
    "        images = []\n",
    "        images.append(photo)\n",
    "        images = np.asarray(images)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            images = torch.from_numpy(images)\n",
    "            if self.cuda:\n",
    "                images = images.cuda()\n",
    "            outputs = self.net(images)\n",
    "            \n",
    "        output_list = []\n",
    "        for i in range(3):\n",
    "            output_list.append(self.yolo_decodes[i](outputs[i]))\n",
    "        output = torch.cat(output_list, 1)\n",
    "        batch_detections = non_max_suppression(output, len(self.class_names),\n",
    "                                                conf_thres=self.confidence,\n",
    "                                                nms_thres=0.3)\n",
    "\n",
    "        try:\n",
    "            batch_detections = batch_detections[0].cpu().numpy()\n",
    "        except:\n",
    "            return image\n",
    "            \n",
    "        top_index = batch_detections[:,4]*batch_detections[:,5] > self.confidence\n",
    "        top_conf = batch_detections[top_index,4]*batch_detections[top_index,5]\n",
    "        top_label = np.array(batch_detections[top_index,-1],np.int32)\n",
    "        top_bboxes = np.array(batch_detections[top_index,:4])\n",
    "        top_xmin, top_ymin, top_xmax, top_ymax = np.expand_dims(top_bboxes[:,0],-1),np.expand_dims(top_bboxes[:,1],-1),np.expand_dims(top_bboxes[:,2],-1),np.expand_dims(top_bboxes[:,3],-1)\n",
    "\n",
    "        # 去掉灰条\n",
    "        boxes = yolo_correct_boxes(top_ymin,top_xmin,top_ymax,top_xmax,np.array([self.model_image_size[0],self.model_image_size[1]]),image_shape)\n",
    "\n",
    "        for i, c in enumerate(top_label):\n",
    "            predicted_class = self.class_names[c]\n",
    "            score = str(top_conf[i])\n",
    "\n",
    "            top, left, bottom, right = boxes[i]\n",
    "            f.write(\"%s %s %s %s %s %s\\n\" % (predicted_class, score[:6], str(int(left)), str(int(top)), str(int(right)),str(int(bottom))))\n",
    "\n",
    "        f.close()\n",
    "        return \n",
    "\n",
    "yolo = mAP_Yolo()\n",
    "image_ids = open('VOCdevkit/VOC2007/ImageSets/Main/test_465_1.txt').read().strip().split()\n",
    "\n",
    "if not os.path.exists(\"./input\"):\n",
    "    os.makedirs(\"./input\")\n",
    "if not os.path.exists(\"./input/detection-results\"):\n",
    "    os.makedirs(\"./input/detection-results\")\n",
    "if not os.path.exists(\"./input/images-optional\"):\n",
    "    os.makedirs(\"./input/images-optional\")\n",
    "\n",
    "\n",
    "for image_id in image_ids:\n",
    "    image_path = \"./VOCdevkit/VOC2007/JPEGImages_465/\"+image_id+\".png\"\n",
    "    image = Image.open(image_path)\n",
    "    yolo.detect_image(image_id,image)\n",
    "    # 开启后在之后计算mAP可以可视化\n",
    "    image.save(\"./input/images-optional/\"+image_id+\".png\")\n",
    "    print(image_id,\" done!\")\n",
    "    \n",
    "\n",
    "print(\"Conversion completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用于1：计算mAP并将结果绘制出来  2：将检测结果在原图上进行绘制  gt用蓝框显示  比较好的预测结果用绿框显示   比较差的预测结果用红框显示\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import operator\n",
    "import sys\n",
    "import argparse\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "MINOVERLAP = 0.5 # default value (defined in the PASCAL VOC2012 challenge)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-na', '--no-animation', help=\"no animation is shown.\", action=\"store_true\")\n",
    "parser.add_argument('-np', '--no-plot', help=\"no plot is shown.\", action=\"store_true\")\n",
    "parser.add_argument('-q', '--quiet', help=\"minimalistic console output.\", action=\"store_true\")\n",
    "# argparse receiving list of classes to be ignored (e.g., python main.py --ignore person book)\n",
    "parser.add_argument('-i', '--ignore', nargs='+', type=str, help=\"ignore a list of classes.\")\n",
    "# argparse receiving list of classes with specific IoU (e.g., python main.py --set-class-iou person 0.7)\n",
    "parser.add_argument('--set-class-iou', nargs='+', type=str, help=\"set IoU for a specific class.\")\n",
    "args = parser.parse_known_args()[0]\n",
    "\n",
    "'''\n",
    "    0,0 ------> x (width)\n",
    "     |\n",
    "     |  (Left,Top)\n",
    "     |      *_________\n",
    "     |      |         |\n",
    "            |         |\n",
    "     y      |_________|\n",
    "  (height)            *\n",
    "                (Right,Bottom)\n",
    "'''\n",
    "\n",
    "# if there are no classes to ignore then replace None by empty list\n",
    "if args.ignore is None:\n",
    "    args.ignore = []\n",
    "\n",
    "specific_iou_flagged = False\n",
    "if args.set_class_iou is not None:\n",
    "    specific_iou_flagged = True\n",
    "\n",
    "# make sure that the cwd() is the location of the python script (so that every path makes sense)\n",
    "os.chdir(os.getcwd())\n",
    "\n",
    "GT_PATH = os.path.join(os.getcwd(), 'input', 'ground-truth')\n",
    "DR_PATH = os.path.join(os.getcwd(), 'input', 'detection-results')\n",
    "# if there are no images then no animation can be shown\n",
    "IMG_PATH = os.path.join(os.getcwd(), 'input', 'images-optional')\n",
    "if os.path.exists(IMG_PATH): \n",
    "    for dirpath, dirnames, files in os.walk(IMG_PATH):\n",
    "        if not files:\n",
    "            # no image files found\n",
    "            args.no_animation = True\n",
    "else:\n",
    "    args.no_animation = True\n",
    "\n",
    "# try to import OpenCV if the user didn't choose the option --no-animation\n",
    "show_animation = False\n",
    "if not args.no_animation:\n",
    "    try:\n",
    "        import cv2\n",
    "        show_animation = True\n",
    "    except ImportError:\n",
    "        print(\"\\\"opencv-python\\\" not found, please install to visualize the results.\")\n",
    "        args.no_animation = True\n",
    "\n",
    "# try to import Matplotlib if the user didn't choose the option --no-plot\n",
    "draw_plot = False\n",
    "if not args.no_plot:\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        draw_plot = True\n",
    "    except ImportError:\n",
    "        print(\"\\\"matplotlib\\\" not found, please install it to get the resulting plots.\")\n",
    "        args.no_plot = True\n",
    "\n",
    "\n",
    "def log_average_miss_rate(prec, rec, num_images):\n",
    "    \"\"\"\n",
    "        log-average miss rate:\n",
    "            Calculated by averaging miss rates at 9 evenly spaced FPPI points\n",
    "            between 10e-2 and 10e0, in log-space.\n",
    "\n",
    "        output:\n",
    "                lamr | log-average miss rate\n",
    "                mr | miss rate\n",
    "                fppi | false positives per image\n",
    "\n",
    "        references:\n",
    "            [1] Dollar, Piotr, et al. \"Pedestrian Detection: An Evaluation of the\n",
    "               State of the Art.\" Pattern Analysis and Machine Intelligence, IEEE\n",
    "               Transactions on 34.4 (2012): 743 - 761.\n",
    "    \"\"\"\n",
    "\n",
    "    # if there were no detections of that class\n",
    "    if prec.size == 0:\n",
    "        lamr = 0\n",
    "        mr = 1\n",
    "        fppi = 0\n",
    "        return lamr, mr, fppi\n",
    "\n",
    "    fppi = (1 - prec)\n",
    "    mr = (1 - rec)\n",
    "\n",
    "    fppi_tmp = np.insert(fppi, 0, -1.0)\n",
    "    mr_tmp = np.insert(mr, 0, 1.0)\n",
    "\n",
    "    # Use 9 evenly spaced reference points in log-space\n",
    "    ref = np.logspace(-2.0, 0.0, num = 9)\n",
    "    for i, ref_i in enumerate(ref):\n",
    "        # np.where() will always find at least 1 index, since min(ref) = 0.01 and min(fppi_tmp) = -1.0\n",
    "        j = np.where(fppi_tmp <= ref_i)[-1][-1]\n",
    "        ref[i] = mr_tmp[j]\n",
    "\n",
    "    # log(0) is undefined, so we use the np.maximum(1e-10, ref)\n",
    "    lamr = math.exp(np.mean(np.log(np.maximum(1e-10, ref))))\n",
    "\n",
    "    return lamr, mr, fppi\n",
    "\n",
    "\"\"\"\n",
    " throw error and exit\n",
    "\"\"\"\n",
    "def error(msg):\n",
    "    print(msg)\n",
    "    sys.exit(0)\n",
    "\n",
    "\"\"\"\n",
    " check if the number is a float between 0.0 and 1.0\n",
    "\"\"\"\n",
    "def is_float_between_0_and_1(value):\n",
    "    try:\n",
    "        val = float(value)\n",
    "        if val > 0.0 and val < 1.0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\"\"\"\n",
    " Calculate the AP given the recall and precision array\n",
    "    1st) We compute a version of the measured precision/recall curve with\n",
    "         precision monotonically decreasing\n",
    "    2nd) We compute the AP as the area under this curve by numerical integration.\n",
    "\"\"\"\n",
    "def voc_ap(rec, prec):\n",
    "    \"\"\"\n",
    "    --- Official matlab code VOC2012---\n",
    "    mrec=[0 ; rec ; 1];\n",
    "    mpre=[0 ; prec ; 0];\n",
    "    for i=numel(mpre)-1:-1:1\n",
    "            mpre(i)=max(mpre(i),mpre(i+1));\n",
    "    end\n",
    "    i=find(mrec(2:end)~=mrec(1:end-1))+1;\n",
    "    ap=sum((mrec(i)-mrec(i-1)).*mpre(i));\n",
    "    \"\"\"\n",
    "    rec.insert(0, 0.0) # insert 0.0 at begining of list\n",
    "    rec.append(1.0) # insert 1.0 at end of list\n",
    "    mrec = rec[:]\n",
    "    prec.insert(0, 0.0) # insert 0.0 at begining of list\n",
    "    prec.append(0.0) # insert 0.0 at end of list\n",
    "    mpre = prec[:]\n",
    "    \"\"\"\n",
    "     This part makes the precision monotonically decreasing\n",
    "        (goes from the end to the beginning)\n",
    "        matlab: for i=numel(mpre)-1:-1:1\n",
    "                    mpre(i)=max(mpre(i),mpre(i+1));\n",
    "    \"\"\"\n",
    "    # matlab indexes start in 1 but python in 0, so I have to do:\n",
    "    #     range(start=(len(mpre) - 2), end=0, step=-1)\n",
    "    # also the python function range excludes the end, resulting in:\n",
    "    #     range(start=(len(mpre) - 2), end=-1, step=-1)\n",
    "    for i in range(len(mpre)-2, -1, -1):\n",
    "        mpre[i] = max(mpre[i], mpre[i+1])\n",
    "    \"\"\"\n",
    "     This part creates a list of indexes where the recall changes\n",
    "        matlab: i=find(mrec(2:end)~=mrec(1:end-1))+1;\n",
    "    \"\"\"\n",
    "    i_list = []\n",
    "    for i in range(1, len(mrec)):\n",
    "        if mrec[i] != mrec[i-1]:\n",
    "            i_list.append(i) # if it was matlab would be i + 1\n",
    "    \"\"\"\n",
    "     The Average Precision (AP) is the area under the curve\n",
    "        (numerical integration)\n",
    "        matlab: ap=sum((mrec(i)-mrec(i-1)).*mpre(i));\n",
    "    \"\"\"\n",
    "    ap = 0.0\n",
    "    for i in i_list:\n",
    "        ap += ((mrec[i]-mrec[i-1])*mpre[i])\n",
    "    return ap, mrec, mpre\n",
    "\n",
    "\n",
    "\"\"\"\n",
    " Convert the lines of a file to a list\n",
    "\"\"\"\n",
    "def file_lines_to_list(path):\n",
    "    # open txt file lines to a list\n",
    "    with open(path) as f:\n",
    "        content = f.readlines()\n",
    "    # remove whitespace characters like `\\n` at the end of each line\n",
    "    content = [x.strip() for x in content]\n",
    "    return content\n",
    "\n",
    "\"\"\"\n",
    " Draws text in image\n",
    "\"\"\"\n",
    "def draw_text_in_image(img, text, pos, color, line_width):\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    fontScale = 1\n",
    "    lineType = 1\n",
    "    bottomLeftCornerOfText = pos\n",
    "    cv2.putText(img, text,\n",
    "            bottomLeftCornerOfText,\n",
    "            font,\n",
    "            fontScale,\n",
    "            color,\n",
    "            lineType)\n",
    "    text_width, _ = cv2.getTextSize(text, font, fontScale, lineType)[0]\n",
    "    return img, (line_width + text_width)\n",
    "\n",
    "\"\"\"\n",
    " Plot - adjust axes\n",
    "\"\"\"\n",
    "def adjust_axes(r, t, fig, axes):\n",
    "    # get text width for re-scaling\n",
    "    bb = t.get_window_extent(renderer=r)\n",
    "    text_width_inches = bb.width / fig.dpi\n",
    "    # get axis width in inches\n",
    "    current_fig_width = fig.get_figwidth()\n",
    "    new_fig_width = current_fig_width + text_width_inches\n",
    "    propotion = new_fig_width / current_fig_width\n",
    "    # get axis limit\n",
    "    x_lim = axes.get_xlim()\n",
    "    axes.set_xlim([x_lim[0], x_lim[1]*propotion])\n",
    "\n",
    "\"\"\"\n",
    " Draw plot using Matplotlib\n",
    "\"\"\"\n",
    "def draw_plot_func(dictionary, n_classes, window_title, plot_title, x_label, output_path, to_show, plot_color, true_p_bar):\n",
    "    # sort the dictionary by decreasing value, into a list of tuples\n",
    "    sorted_dic_by_value = sorted(dictionary.items(), key=operator.itemgetter(1))\n",
    "    # unpacking the list of tuples into two lists\n",
    "    sorted_keys, sorted_values = zip(*sorted_dic_by_value)\n",
    "    # \n",
    "    if true_p_bar != \"\":\n",
    "        \"\"\"\n",
    "         Special case to draw in:\n",
    "            - green -> TP: True Positives (object detected and matches ground-truth)\n",
    "            - red -> FP: False Positives (object detected but does not match ground-truth)\n",
    "            - pink -> FN: False Negatives (object not detected but present in the ground-truth)\n",
    "        \"\"\"\n",
    "        fp_sorted = []\n",
    "        tp_sorted = []\n",
    "        for key in sorted_keys:\n",
    "            fp_sorted.append(dictionary[key] - true_p_bar[key])\n",
    "            tp_sorted.append(true_p_bar[key])\n",
    "        plt.barh(range(n_classes), fp_sorted, align='center', color='crimson', label='False Positive')\n",
    "        plt.barh(range(n_classes), tp_sorted, align='center', color='forestgreen', label='True Positive', left=fp_sorted)\n",
    "        # add legend\n",
    "        plt.legend(loc='lower right')\n",
    "        \"\"\"\n",
    "         Write number on side of bar\n",
    "        \"\"\"\n",
    "        fig = plt.gcf() # gcf - get current figure\n",
    "        axes = plt.gca()\n",
    "        r = fig.canvas.get_renderer()\n",
    "        for i, val in enumerate(sorted_values):\n",
    "            fp_val = fp_sorted[i]\n",
    "            tp_val = tp_sorted[i]\n",
    "            fp_str_val = \" \" + str(fp_val)\n",
    "            tp_str_val = fp_str_val + \" \" + str(tp_val)\n",
    "            # trick to paint multicolor with offset:\n",
    "            # first paint everything and then repaint the first number\n",
    "            t = plt.text(val, i, tp_str_val, color='forestgreen', va='center', fontweight='bold')\n",
    "            plt.text(val, i, fp_str_val, color='crimson', va='center', fontweight='bold')\n",
    "            if i == (len(sorted_values)-1): # largest bar\n",
    "                adjust_axes(r, t, fig, axes)\n",
    "    else:\n",
    "        plt.barh(range(n_classes), sorted_values, color=plot_color)\n",
    "        \"\"\"\n",
    "         Write number on side of bar\n",
    "        \"\"\"\n",
    "        fig = plt.gcf() # gcf - get current figure\n",
    "        axes = plt.gca()\n",
    "        r = fig.canvas.get_renderer()\n",
    "        for i, val in enumerate(sorted_values):\n",
    "            str_val = \" \" + str(val) # add a space before\n",
    "            if val < 1.0:\n",
    "                str_val = \" {0:.2f}\".format(val)\n",
    "            t = plt.text(val, i, str_val, color=plot_color, va='center', fontweight='bold')\n",
    "            # re-set axes to show number inside the figure\n",
    "            if i == (len(sorted_values)-1): # largest bar\n",
    "                adjust_axes(r, t, fig, axes)\n",
    "    # set window title\n",
    "    fig.canvas.set_window_title(window_title)\n",
    "    # write classes in y axis\n",
    "    tick_font_size = 12\n",
    "    plt.yticks(range(n_classes), sorted_keys, fontsize=tick_font_size)\n",
    "    \"\"\"\n",
    "     Re-scale height accordingly\n",
    "    \"\"\"\n",
    "    init_height = fig.get_figheight()\n",
    "    # comput the matrix height in points and inches\n",
    "    dpi = fig.dpi\n",
    "    height_pt = n_classes * (tick_font_size * 1.4) # 1.4 (some spacing)\n",
    "    height_in = height_pt / dpi\n",
    "    # compute the required figure height \n",
    "    top_margin = 0.15 # in percentage of the figure height\n",
    "    bottom_margin = 0.05 # in percentage of the figure height\n",
    "    figure_height = height_in / (1 - top_margin - bottom_margin)\n",
    "    # set new height\n",
    "    if figure_height > init_height:\n",
    "        fig.set_figheight(figure_height)\n",
    "\n",
    "    # set plot title\n",
    "    plt.title(plot_title, fontsize=14)\n",
    "    # set axis titles\n",
    "    # plt.xlabel('classes')\n",
    "    plt.xlabel(x_label, fontsize='large')\n",
    "    # adjust size of window\n",
    "    fig.tight_layout()\n",
    "    # save the plot\n",
    "    fig.savefig(output_path)\n",
    "    # show image\n",
    "    if to_show:\n",
    "        plt.show()\n",
    "    # close the plot\n",
    "    plt.close()\n",
    "\n",
    "\"\"\"\n",
    " Create a \".temp_files/\" and \"output/\" directory\n",
    "\"\"\"\n",
    "TEMP_FILES_PATH = \".temp_files\"\n",
    "if not os.path.exists(TEMP_FILES_PATH): # if it doesn't exist already\n",
    "    os.makedirs(TEMP_FILES_PATH)\n",
    "output_files_path = \"output1\"\n",
    "if os.path.exists(output_files_path): # if it exist already\n",
    "    # reset the output directory\n",
    "    shutil.rmtree(output_files_path)\n",
    "\n",
    "os.makedirs(output_files_path)\n",
    "if draw_plot:\n",
    "    os.makedirs(os.path.join(output_files_path, \"classes\"))\n",
    "if show_animation:\n",
    "    os.makedirs(os.path.join(output_files_path, \"images\", \"detections_one_by_one\"))\n",
    "\n",
    "\"\"\"\n",
    " ground-truth\n",
    "     Load each of the ground-truth files into a temporary \".json\" file.\n",
    "     Create a list of all the class names present in the ground-truth (gt_classes).\n",
    "\"\"\"\n",
    "# get a list with the ground-truth files\n",
    "ground_truth_files_list = glob.glob(GT_PATH + '/*.txt')\n",
    "if len(ground_truth_files_list) == 0:\n",
    "    error(\"Error: No ground-truth files found!\")\n",
    "ground_truth_files_list.sort()\n",
    "# dictionary with counter per class\n",
    "gt_counter_per_class = {}\n",
    "counter_images_per_class = {}\n",
    "\n",
    "gt_files = []\n",
    "for txt_file in ground_truth_files_list:\n",
    "    #print(txt_file)\n",
    "    file_id = txt_file.split(\".txt\", 1)[0]\n",
    "    file_id = os.path.basename(os.path.normpath(file_id))\n",
    "    # check if there is a correspondent detection-results file\n",
    "    temp_path = os.path.join(DR_PATH, (file_id + \".txt\"))\n",
    "    if not os.path.exists(temp_path):\n",
    "        error_msg = \"Error. File not found: {}\\n\".format(temp_path)\n",
    "        error_msg += \"(You can avoid this error message by running extra/intersect-gt-and-dr.py)\"\n",
    "        error(error_msg)\n",
    "    lines_list = file_lines_to_list(txt_file)\n",
    "    # create ground-truth dictionary\n",
    "    bounding_boxes = []\n",
    "    is_difficult = False\n",
    "    already_seen_classes = []\n",
    "    for line in lines_list:\n",
    "        try:\n",
    "            if \"difficult\" in line:\n",
    "                    class_name, left, top, right, bottom, _difficult = line.split()\n",
    "                    is_difficult = True\n",
    "            else:\n",
    "                    class_name, left, top, right, bottom = line.split()\n",
    "        except ValueError:\n",
    "            error_msg = \"Error: File \" + txt_file + \" in the wrong format.\\n\"\n",
    "            error_msg += \" Expected: <class_name> <left> <top> <right> <bottom> ['difficult']\\n\"\n",
    "            error_msg += \" Received: \" + line\n",
    "            error_msg += \"\\n\\nIf you have a <class_name> with spaces between words you should remove them\\n\"\n",
    "            error_msg += \"by running the script \\\"remove_space.py\\\" or \\\"rename_class.py\\\" in the \\\"extra/\\\" folder.\"\n",
    "            error(error_msg)\n",
    "        # check if class is in the ignore list, if yes skip\n",
    "        if class_name in args.ignore:\n",
    "            continue\n",
    "        bbox = left + \" \" + top + \" \" + right + \" \" +bottom\n",
    "        if is_difficult:\n",
    "            bounding_boxes.append({\"class_name\":class_name, \"bbox\":bbox, \"used\":False, \"difficult\":True})\n",
    "            is_difficult = False\n",
    "        else:\n",
    "            bounding_boxes.append({\"class_name\":class_name, \"bbox\":bbox, \"used\":False})\n",
    "            # count that object\n",
    "            if class_name in gt_counter_per_class:\n",
    "                gt_counter_per_class[class_name] += 1\n",
    "            else:\n",
    "                # if class didn't exist yet\n",
    "                gt_counter_per_class[class_name] = 1\n",
    "\n",
    "            if class_name not in already_seen_classes:\n",
    "                if class_name in counter_images_per_class:\n",
    "                    counter_images_per_class[class_name] += 1\n",
    "                else:\n",
    "                    # if class didn't exist yet\n",
    "                    counter_images_per_class[class_name] = 1\n",
    "                already_seen_classes.append(class_name)\n",
    "\n",
    "\n",
    "    # dump bounding_boxes into a \".json\" file\n",
    "    new_temp_file = TEMP_FILES_PATH + \"/\" + file_id + \"_ground_truth.json\"\n",
    "    gt_files.append(new_temp_file)\n",
    "    with open(new_temp_file, 'w') as outfile:\n",
    "        json.dump(bounding_boxes, outfile)\n",
    "\n",
    "gt_classes = list(gt_counter_per_class.keys())\n",
    "# let's sort the classes alphabetically\n",
    "gt_classes = sorted(gt_classes)\n",
    "n_classes = len(gt_classes)\n",
    "#print(gt_classes)\n",
    "#print(gt_counter_per_class)\n",
    "\n",
    "\"\"\"\n",
    " Check format of the flag --set-class-iou (if used)\n",
    "    e.g. check if class exists\n",
    "\"\"\"\n",
    "if specific_iou_flagged:\n",
    "    n_args = len(args.set_class_iou)\n",
    "    error_msg = \\\n",
    "        '\\n --set-class-iou [class_1] [IoU_1] [class_2] [IoU_2] [...]'\n",
    "    if n_args % 2 != 0:\n",
    "        error('Error, missing arguments. Flag usage:' + error_msg)\n",
    "    # [class_1] [IoU_1] [class_2] [IoU_2]\n",
    "    # specific_iou_classes = ['class_1', 'class_2']\n",
    "    specific_iou_classes = args.set_class_iou[::2] # even\n",
    "    # iou_list = ['IoU_1', 'IoU_2']\n",
    "    iou_list = args.set_class_iou[1::2] # odd\n",
    "    if len(specific_iou_classes) != len(iou_list):\n",
    "        error('Error, missing arguments. Flag usage:' + error_msg)\n",
    "    for tmp_class in specific_iou_classes:\n",
    "        if tmp_class not in gt_classes:\n",
    "                    error('Error, unknown class \\\"' + tmp_class + '\\\". Flag usage:' + error_msg)\n",
    "    for num in iou_list:\n",
    "        if not is_float_between_0_and_1(num):\n",
    "            error('Error, IoU must be between 0.0 and 1.0. Flag usage:' + error_msg)\n",
    "\n",
    "\"\"\"\n",
    " detection-results\n",
    "     Load each of the detection-results files into a temporary \".json\" file.\n",
    "\"\"\"\n",
    "# get a list with the detection-results files\n",
    "dr_files_list = glob.glob(DR_PATH + '/*.txt')\n",
    "dr_files_list.sort()\n",
    "\n",
    "for class_index, class_name in enumerate(gt_classes):\n",
    "    bounding_boxes = []\n",
    "    for txt_file in dr_files_list:\n",
    "        #print(txt_file)\n",
    "        # the first time it checks if all the corresponding ground-truth files exist\n",
    "        file_id = txt_file.split(\".txt\",1)[0]\n",
    "        file_id = os.path.basename(os.path.normpath(file_id))\n",
    "        temp_path = os.path.join(GT_PATH, (file_id + \".txt\"))\n",
    "        if class_index == 0:\n",
    "            if not os.path.exists(temp_path):\n",
    "                error_msg = \"Error. File not found: {}\\n\".format(temp_path)\n",
    "                error_msg += \"(You can avoid this error message by running extra/intersect-gt-and-dr.py)\"\n",
    "                error(error_msg)\n",
    "        lines = file_lines_to_list(txt_file)\n",
    "        for line in lines:\n",
    "            try:\n",
    "                tmp_class_name, confidence, left, top, right, bottom = line.split()\n",
    "            except ValueError:\n",
    "                error_msg = \"Error: File \" + txt_file + \" in the wrong format.\\n\"\n",
    "                error_msg += \" Expected: <class_name> <confidence> <left> <top> <right> <bottom>\\n\"\n",
    "                error_msg += \" Received: \" + line\n",
    "                error(error_msg)\n",
    "            if tmp_class_name == class_name:\n",
    "                #print(\"match\")\n",
    "                bbox = left + \" \" + top + \" \" + right + \" \" +bottom\n",
    "                bounding_boxes.append({\"confidence\":confidence, \"file_id\":file_id, \"bbox\":bbox})\n",
    "                #print(bounding_boxes)\n",
    "    # sort detection-results by decreasing confidence\n",
    "    bounding_boxes.sort(key=lambda x:float(x['confidence']), reverse=True)\n",
    "    with open(TEMP_FILES_PATH + \"/\" + class_name + \"_dr.json\", 'w') as outfile:\n",
    "        json.dump(bounding_boxes, outfile)\n",
    "\n",
    "\"\"\"\n",
    " Calculate the AP for each class\n",
    "\"\"\"\n",
    "sum_AP = 0.0\n",
    "ap_dictionary = {}\n",
    "lamr_dictionary = {}\n",
    "# open file to store the output\n",
    "with open(output_files_path + \"/output.txt\", 'w') as output_file:\n",
    "    output_file.write(\"# AP and precision/recall per class\\n\")\n",
    "    count_true_positives = {}\n",
    "    for class_index, class_name in enumerate(gt_classes):\n",
    "        count_true_positives[class_name] = 0\n",
    "        \"\"\"\n",
    "         Load detection-results of that class\n",
    "        \"\"\"\n",
    "        dr_file = TEMP_FILES_PATH + \"/\" + class_name + \"_dr.json\"\n",
    "        dr_data = json.load(open(dr_file))\n",
    "\n",
    "        \"\"\"\n",
    "         Assign detection-results to ground-truth objects\n",
    "        \"\"\"\n",
    "        nd = len(dr_data)\n",
    "        tp = [0] * nd # creates an array of zeros of size nd\n",
    "        fp = [0] * nd\n",
    "        for idx, detection in enumerate(dr_data):\n",
    "            file_id = detection[\"file_id\"]\n",
    "            if show_animation:\n",
    "                # find ground truth image\n",
    "                ground_truth_img = glob.glob1(IMG_PATH, file_id + \".*\")\n",
    "                #tifCounter = len(glob.glob1(myPath,\"*.tif\"))\n",
    "                if len(ground_truth_img) == 0:\n",
    "                    error(\"Error. Image not found with id: \" + file_id)\n",
    "                elif len(ground_truth_img) > 1:\n",
    "                    error(\"Error. Multiple image with id: \" + file_id)\n",
    "                else: # found image\n",
    "                    #print(IMG_PATH + \"/\" + ground_truth_img[0])\n",
    "                    # Load image\n",
    "                    img = cv2.imread(IMG_PATH + \"/\" + ground_truth_img[0])\n",
    "                    # load image with draws of multiple detections\n",
    "                    img_cumulative_path = output_files_path + \"/images/\" + ground_truth_img[0]\n",
    "                    if os.path.isfile(img_cumulative_path):\n",
    "                        img_cumulative = cv2.imread(img_cumulative_path)\n",
    "                    else:\n",
    "                        img_cumulative = img.copy()\n",
    "                    # Add bottom border to image\n",
    "                    bottom_border = 60\n",
    "                    BLACK = [0, 0, 0]\n",
    "                    img = cv2.copyMakeBorder(img, 0, bottom_border, 0, 0, cv2.BORDER_CONSTANT, value=BLACK)\n",
    "            # assign detection-results to ground truth object if any\n",
    "            # open ground-truth with that file_id\n",
    "            gt_file = TEMP_FILES_PATH + \"/\" + file_id + \"_ground_truth.json\"\n",
    "            ground_truth_data = json.load(open(gt_file))\n",
    "            ovmax = -1\n",
    "            gt_match = -1\n",
    "            # load detected object bounding-box\n",
    "            bb = [ float(x) for x in detection[\"bbox\"].split() ]\n",
    "            for obj in ground_truth_data:\n",
    "                # look for a class_name match\n",
    "                if obj[\"class_name\"] == class_name:\n",
    "                    bbgt = [ float(x) for x in obj[\"bbox\"].split() ]\n",
    "                    bi = [max(bb[0],bbgt[0]), max(bb[1],bbgt[1]), min(bb[2],bbgt[2]), min(bb[3],bbgt[3])]\n",
    "                    iw = bi[2] - bi[0] + 1\n",
    "                    ih = bi[3] - bi[1] + 1\n",
    "                    if iw > 0 and ih > 0:\n",
    "                        # compute overlap (IoU) = area of intersection / area of union\n",
    "                        ua = (bb[2] - bb[0] + 1) * (bb[3] - bb[1] + 1) + (bbgt[2] - bbgt[0]\n",
    "                                        + 1) * (bbgt[3] - bbgt[1] + 1) - iw * ih\n",
    "                        ov = iw * ih / ua\n",
    "                        if ov > ovmax:\n",
    "                            ovmax = ov\n",
    "                            gt_match = obj\n",
    "\n",
    "            # assign detection as true positive/don't care/false positive\n",
    "            if show_animation:\n",
    "                status = \"NO MATCH FOUND!\" # status is only used in the animation\n",
    "            # set minimum overlap\n",
    "            min_overlap = MINOVERLAP\n",
    "            if specific_iou_flagged:\n",
    "                if class_name in specific_iou_classes:\n",
    "                    index = specific_iou_classes.index(class_name)\n",
    "                    min_overlap = float(iou_list[index])\n",
    "            if ovmax >= min_overlap:\n",
    "                if \"difficult\" not in gt_match:\n",
    "                        if not bool(gt_match[\"used\"]):\n",
    "                            # true positive\n",
    "                            tp[idx] = 1\n",
    "                            gt_match[\"used\"] = True\n",
    "                            count_true_positives[class_name] += 1\n",
    "                            # update the \".json\" file\n",
    "                            with open(gt_file, 'w') as f:\n",
    "                                    f.write(json.dumps(ground_truth_data))\n",
    "                            if show_animation:\n",
    "                                status = \"MATCH!\"\n",
    "                        else:\n",
    "                            # false positive (multiple detection)\n",
    "                            fp[idx] = 1\n",
    "                            if show_animation:\n",
    "                                status = \"REPEATED MATCH!\"\n",
    "            else:\n",
    "                # false positive\n",
    "                fp[idx] = 1\n",
    "                if ovmax > 0:\n",
    "                    status = \"INSUFFICIENT OVERLAP\"\n",
    "\n",
    "            \"\"\"\n",
    "             Draw image to show animation\n",
    "            \"\"\"\n",
    "            if show_animation:\n",
    "                height, widht = img.shape[:2]\n",
    "                # colors (OpenCV works with BGR)\n",
    "                white = (255,255,255)\n",
    "                light_blue = (255,200,100)\n",
    "                green = (0,255,0)\n",
    "                light_red = (30,30,255)\n",
    "                # 1st line\n",
    "                margin = 10\n",
    "                v_pos = int(height - margin - (bottom_border / 2.0))\n",
    "                text = \"Image: \" + ground_truth_img[0] + \" \"\n",
    "                img, line_width = draw_text_in_image(img, text, (margin, v_pos), white, 0)\n",
    "                text = \"Class [\" + str(class_index) + \"/\" + str(n_classes) + \"]: \" + class_name + \" \"\n",
    "                img, line_width = draw_text_in_image(img, text, (margin + line_width, v_pos), light_blue, line_width)\n",
    "                if ovmax != -1:\n",
    "                    color = light_red\n",
    "                    if status == \"INSUFFICIENT OVERLAP\":\n",
    "                        text = \"IoU: {0:.2f}% \".format(ovmax*100) + \"< {0:.2f}% \".format(min_overlap*100)\n",
    "                    else:\n",
    "                        text = \"IoU: {0:.2f}% \".format(ovmax*100) + \">= {0:.2f}% \".format(min_overlap*100)\n",
    "                        color = green\n",
    "                    img, _ = draw_text_in_image(img, text, (margin + line_width, v_pos), color, line_width)\n",
    "                # 2nd line\n",
    "                v_pos += int(bottom_border / 2.0)\n",
    "                rank_pos = str(idx+1) # rank position (idx starts at 0)\n",
    "                text = \"Detection #rank: \" + rank_pos + \" confidence: {0:.2f}% \".format(float(detection[\"confidence\"])*100)\n",
    "                img, line_width = draw_text_in_image(img, text, (margin, v_pos), white, 0)\n",
    "                color = light_red\n",
    "                if status == \"MATCH!\":\n",
    "                    color = green\n",
    "                text = \"Result: \" + status + \" \"\n",
    "                img, line_width = draw_text_in_image(img, text, (margin + line_width, v_pos), color, line_width)\n",
    "\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                if ovmax > 0: # if there is intersections between the bounding-boxes\n",
    "                    bbgt = [ int(round(float(x))) for x in gt_match[\"bbox\"].split() ]\n",
    "                    cv2.rectangle(img,(bbgt[0],bbgt[1]),(bbgt[2],bbgt[3]),light_blue,2)\n",
    "                    #cv2.rectangle(img_cumulative,(bbgt[0],bbgt[1]),(bbgt[2],bbgt[3]),light_blue,2)\n",
    "                    #cv2.putText(img_cumulative, class_name, (bbgt[0],bbgt[1] - 5), font, 0.6, light_blue, 1, cv2.LINE_AA)\n",
    "                    #上面两行是绘制ground truth的蓝色框   这里不想显示的话先注释掉-----------------------------------------------\n",
    "                bb = [int(i) for i in bb]\n",
    "                cv2.rectangle(img,(bb[0],bb[1]),(bb[2],bb[3]),color,2)\n",
    "                cv2.rectangle(img_cumulative,(bb[0],bb[1]),(bb[2],bb[3]),color,2)\n",
    "                #上面这行是绘制truth positive绿色框 或者 false positive红色框\n",
    "                cv2.putText(img_cumulative, class_name, (bb[0],bb[1] - 5), font, 0.6, color, 1, cv2.LINE_AA)\n",
    "                # show image\n",
    "                cv2.imshow(\"Animation\", img)\n",
    "                cv2.waitKey(20) # show for 20 ms\n",
    "                # save image to output\n",
    "                output_img_path = output_files_path + \"/images/detections_one_by_one/\" + class_name + \"_detection\" + str(idx) + \".png\"\n",
    "                cv2.imwrite(output_img_path, img)\n",
    "                # save the image with all the objects drawn to it\n",
    "                cv2.imwrite(img_cumulative_path, img_cumulative)\n",
    "\n",
    "        #print(tp)\n",
    "        # compute precision/recall\n",
    "        cumsum = 0\n",
    "        for idx, val in enumerate(fp):\n",
    "            fp[idx] += cumsum\n",
    "            cumsum += val\n",
    "        cumsum = 0\n",
    "        for idx, val in enumerate(tp):\n",
    "            tp[idx] += cumsum\n",
    "            cumsum += val\n",
    "        #print(tp)\n",
    "        rec = tp[:]\n",
    "        for idx, val in enumerate(tp):\n",
    "            rec[idx] = float(tp[idx]) / gt_counter_per_class[class_name]\n",
    "        #print(rec)\n",
    "        prec = tp[:]\n",
    "        for idx, val in enumerate(tp):\n",
    "            prec[idx] = float(tp[idx]) / (fp[idx] + tp[idx])\n",
    "        #print(prec)\n",
    "\n",
    "        ap, mrec, mprec = voc_ap(rec[:], prec[:])\n",
    "        sum_AP += ap\n",
    "        text = \"{0:.2f}%\".format(ap*100) + \" = \" + class_name + \" AP \" #class_name + \" AP = {0:.2f}%\".format(ap*100)\n",
    "        \"\"\"\n",
    "         Write to output.txt\n",
    "        \"\"\"\n",
    "        rounded_prec = [ '%.2f' % elem for elem in prec ]\n",
    "        rounded_rec = [ '%.2f' % elem for elem in rec ]\n",
    "        output_file.write(text + \"\\n Precision: \" + str(rounded_prec) + \"\\n Recall :\" + str(rounded_rec) + \"\\n\\n\")\n",
    "        if not args.quiet:\n",
    "            print(text)\n",
    "        ap_dictionary[class_name] = ap\n",
    "\n",
    "        n_images = counter_images_per_class[class_name]\n",
    "        lamr, mr, fppi = log_average_miss_rate(np.array(prec), np.array(rec), n_images)\n",
    "        lamr_dictionary[class_name] = lamr\n",
    "\n",
    "        \"\"\"\n",
    "         Draw plot\n",
    "        \"\"\"\n",
    "        if draw_plot:\n",
    "            plt.plot(rec, prec, '-o')\n",
    "            # add a new penultimate point to the list (mrec[-2], 0.0)\n",
    "            # since the last line segment (and respective area) do not affect the AP value\n",
    "            area_under_curve_x = mrec[:-1] + [mrec[-2]] + [mrec[-1]]\n",
    "            area_under_curve_y = mprec[:-1] + [0.0] + [mprec[-1]]\n",
    "            plt.fill_between(area_under_curve_x, 0, area_under_curve_y, alpha=0.2, edgecolor='r')\n",
    "            # set window title\n",
    "            fig = plt.gcf() # gcf - get current figure\n",
    "            fig.canvas.set_window_title('AP ' + class_name)\n",
    "            # set plot title\n",
    "            plt.title('class: ' + text)\n",
    "            #plt.suptitle('This is a somewhat long figure title', fontsize=16)\n",
    "            # set axis titles\n",
    "            plt.xlabel('Recall')\n",
    "            plt.ylabel('Precision')\n",
    "            # optional - set axes\n",
    "            axes = plt.gca() # gca - get current axes\n",
    "            axes.set_xlim([0.0,1.0])\n",
    "            axes.set_ylim([0.0,1.05]) # .05 to give some extra space\n",
    "            # Alternative option -> wait for button to be pressed\n",
    "            #while not plt.waitforbuttonpress(): pass # wait for key display\n",
    "            # Alternative option -> normal display\n",
    "            #plt.show()\n",
    "            # save the plot\n",
    "            fig.savefig(output_files_path + \"/classes/\" + class_name + \".png\")\n",
    "            plt.cla() # clear axes for next plot\n",
    "\n",
    "    if show_animation:\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    output_file.write(\"\\n# mAP of all classes\\n\")\n",
    "    mAP = sum_AP / n_classes\n",
    "    text = \"mAP = {0:.2f}%\".format(mAP*100)\n",
    "    output_file.write(text + \"\\n\")\n",
    "    print(text)\n",
    "\n",
    "\"\"\"\n",
    " Draw false negatives\n",
    "\"\"\"\n",
    "if show_animation:\n",
    "    pink = (203,192,255)\n",
    "    for tmp_file in gt_files:\n",
    "        ground_truth_data = json.load(open(tmp_file))\n",
    "        #print(ground_truth_data)\n",
    "        # get name of corresponding image\n",
    "        start = TEMP_FILES_PATH + '/'\n",
    "        img_id = tmp_file[tmp_file.find(start)+len(start):tmp_file.rfind('_ground_truth.json')]\n",
    "        img_cumulative_path = output_files_path + \"/images/\" + img_id + \".png\"\n",
    "        img = cv2.imread(img_cumulative_path)\n",
    "        if img is None:\n",
    "            img_path = IMG_PATH + '/' + img_id + \".png\"\n",
    "            img = cv2.imread(img_path)\n",
    "        # draw false negatives\n",
    "        for obj in ground_truth_data:\n",
    "            if not obj['used']:\n",
    "                bbgt = [ int(round(float(x))) for x in obj[\"bbox\"].split() ]\n",
    "                #cv2.rectangle(img,(bbgt[0],bbgt[1]),(bbgt[2],bbgt[3]),pink,2)  #这里是绘制false negative的粉色框   这里不要先注释掉-------\n",
    "        cv2.imwrite(img_cumulative_path, img)\n",
    "\n",
    "# remove the temp_files directory\n",
    "shutil.rmtree(TEMP_FILES_PATH)\n",
    "\n",
    "\"\"\"\n",
    " Count total of detection-results\n",
    "\"\"\"\n",
    "# iterate through all the files\n",
    "det_counter_per_class = {}\n",
    "for txt_file in dr_files_list:\n",
    "    # get lines to list\n",
    "    lines_list = file_lines_to_list(txt_file)\n",
    "    for line in lines_list:\n",
    "        class_name = line.split()[0]\n",
    "        # check if class is in the ignore list, if yes skip\n",
    "        if class_name in args.ignore:\n",
    "            continue\n",
    "        # count that object\n",
    "        if class_name in det_counter_per_class:\n",
    "            det_counter_per_class[class_name] += 1\n",
    "        else:\n",
    "            # if class didn't exist yet\n",
    "            det_counter_per_class[class_name] = 1\n",
    "#print(det_counter_per_class)\n",
    "dr_classes = list(det_counter_per_class.keys())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    " Plot the total number of occurences of each class in the ground-truth\n",
    "\"\"\"\n",
    "if draw_plot:\n",
    "    window_title = \"ground-truth-info\"\n",
    "    plot_title = \"ground-truth\\n\"\n",
    "    plot_title += \"(\" + str(len(ground_truth_files_list)) + \" files and \" + str(n_classes) + \" classes)\"\n",
    "    x_label = \"Number of objects per class\"\n",
    "    output_path = output_files_path + \"/ground-truth-info.png\"\n",
    "    to_show = False\n",
    "    plot_color = 'forestgreen'\n",
    "    draw_plot_func(\n",
    "        gt_counter_per_class,\n",
    "        n_classes,\n",
    "        window_title,\n",
    "        plot_title,\n",
    "        x_label,\n",
    "        output_path,\n",
    "        to_show,\n",
    "        plot_color,\n",
    "        '',\n",
    "        )\n",
    "\n",
    "\"\"\"\n",
    " Write number of ground-truth objects per class to results.txt\n",
    "\"\"\"\n",
    "with open(output_files_path + \"/output.txt\", 'a') as output_file:\n",
    "    output_file.write(\"\\n# Number of ground-truth objects per class\\n\")\n",
    "    for class_name in sorted(gt_counter_per_class):\n",
    "        output_file.write(class_name + \": \" + str(gt_counter_per_class[class_name]) + \"\\n\")\n",
    "\n",
    "\"\"\"\n",
    " Finish counting true positives\n",
    "\"\"\"\n",
    "for class_name in dr_classes:\n",
    "    # if class exists in detection-result but not in ground-truth then there are no true positives in that class\n",
    "    if class_name not in gt_classes:\n",
    "        count_true_positives[class_name] = 0\n",
    "#print(count_true_positives)\n",
    "\n",
    "\"\"\"\n",
    " Plot the total number of occurences of each class in the \"detection-results\" folder\n",
    "\"\"\"\n",
    "if draw_plot:\n",
    "    window_title = \"detection-results-info\"\n",
    "    # Plot title\n",
    "    plot_title = \"detection-results\\n\"\n",
    "    plot_title += \"(\" + str(len(dr_files_list)) + \" files and \"\n",
    "    count_non_zero_values_in_dictionary = sum(int(x) > 0 for x in list(det_counter_per_class.values()))\n",
    "    plot_title += str(count_non_zero_values_in_dictionary) + \" detected classes)\"\n",
    "    # end Plot title\n",
    "    x_label = \"Number of objects per class\"\n",
    "    output_path = output_files_path + \"/detection-results-info.png\"\n",
    "    to_show = False\n",
    "    plot_color = 'forestgreen'\n",
    "    true_p_bar = count_true_positives\n",
    "    draw_plot_func(\n",
    "        det_counter_per_class,\n",
    "        len(det_counter_per_class),\n",
    "        window_title,\n",
    "        plot_title,\n",
    "        x_label,\n",
    "        output_path,\n",
    "        to_show,\n",
    "        plot_color,\n",
    "        true_p_bar\n",
    "        )\n",
    "\n",
    "\"\"\"\n",
    " Write number of detected objects per class to output.txt\n",
    "\"\"\"\n",
    "with open(output_files_path + \"/output.txt\", 'a') as output_file:\n",
    "    output_file.write(\"\\n# Number of detected objects per class\\n\")\n",
    "    for class_name in sorted(dr_classes):\n",
    "        n_det = det_counter_per_class[class_name]\n",
    "        text = class_name + \": \" + str(n_det)\n",
    "        text += \" (tp:\" + str(count_true_positives[class_name]) + \"\"\n",
    "        text += \", fp:\" + str(n_det - count_true_positives[class_name]) + \")\\n\"\n",
    "        output_file.write(text)\n",
    "\n",
    "\"\"\"\n",
    " Draw log-average miss rate plot (Show lamr of all classes in decreasing order)\n",
    "\"\"\"\n",
    "if draw_plot:\n",
    "    window_title = \"lamr\"\n",
    "    plot_title = \"log-average miss rate\"\n",
    "    x_label = \"log-average miss rate\"\n",
    "    output_path = output_files_path + \"/lamr.png\"\n",
    "    to_show = False\n",
    "    plot_color = 'royalblue'\n",
    "    draw_plot_func(\n",
    "        lamr_dictionary,\n",
    "        n_classes,\n",
    "        window_title,\n",
    "        plot_title,\n",
    "        x_label,\n",
    "        output_path,\n",
    "        to_show,\n",
    "        plot_color,\n",
    "        \"\"\n",
    "        )\n",
    "\n",
    "\"\"\"\n",
    " Draw mAP plot (Show AP's of all classes in decreasing order)\n",
    "\"\"\"\n",
    "if draw_plot:\n",
    "    window_title = \"mAP\"\n",
    "    plot_title = \"mAP = {0:.2f}%\".format(mAP*100)\n",
    "    x_label = \"Average Precision\"\n",
    "    output_path = output_files_path + \"/mAP.png\"\n",
    "    to_show = True\n",
    "    plot_color = 'royalblue'\n",
    "    draw_plot_func(\n",
    "        ap_dictionary,\n",
    "        n_classes,\n",
    "        window_title,\n",
    "        plot_title,\n",
    "        x_label,\n",
    "        output_path,\n",
    "        to_show,\n",
    "        plot_color,\n",
    "        \"\"\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "00959756d2597ff90f1f5ac84f277ecbd8492a80bbcc5cacd13a89582ab7de4a"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}